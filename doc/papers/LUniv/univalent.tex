\documentclass{llncs}

\usepackage{xcolor}
\usepackage{enumitem,amsmath,amssymb}
\usepackage{stmaryrd}    % needed for \mapsfrom
\usepackage[linesnumbered,boxed,noline,noend]{algorithm2e}
\usepackage{bussproofs}
\def\defaultHypSeparation{\hskip.1in}

\usepackage{tikz}
\usepackage{subfig}
\usepackage{array,booktabs,multirow}

\usepackage{logictools}
\usepackage{prooftheory}
\usepackage{comment}
\usepackage{mathenvironments}


\title{Propositional Resolution Proof Compression by Lowering Nodes}

\author{
  Joseph Boudou\inst{1}
  \thanks{This work was supported by the Google Summer of Code program.}
  \and 
  Bruno Woltzenlogel Paleo\inst{2}
}

\authorrunning{J.\~Boudou \and B.\~Woltzenlogel Paleo}

\institute{
  Universit\'e Paul Sabatier, Toulouse \\
  \email{joseph.boudou@matabio.net}
  \and 
  Vienna University of Technology \\
  \email{bruno@logic.at}
}




\includeonly{}
\begin{document}

\maketitle


\begin{abstract}
This paper describes a generalization of the {\LowerUnits} algorithm \cite{LURPI}
for the compression of propositional resolution proofs. 
The generalized algorithm, here called {\LowerUnivalents}, is
able to lower not only units but also proof nodes containing non-unit clauses, 
provided that their literals satisfy some additional conditions. 
A formal proof that {\LowerUnivalents} always compresses more than {\LowerUnits} is shown, 
and both algorithms are empirically compared on
thousands of proofs produced by the SMT-Solver \veriT.
\end{abstract}



\section{Introduction}

Sat-solvers are among the most successful automated deduction tools available today. As standalone
tools, they can already be applied to a wide range of problems, especially considering that, due to
the NP-completeness of propositional satisfiability \cite{cook}, any NP problem can be encoded as a
propositional formula. And, nevertheless, despite the theoretical difficulty associated with NP
problems, state-of-the-art sat-solving techniques perform surprisingly well in practice
\cite{sat-competition}. With the aim of leveraging this efficiency, sat-solvers have been embedded
into various other automated deduction tools that target problems described in more expressive
logics. The most prominent examples are SMT-solvers \cite{veriT}, for checking satisfiability modulo
theories for equality, linear arithmetic, bit-vectors, arrays and others. But more recently,
interactive proof assistants \cite{isabelle-blanchette-boehme} and automated first-order
\cite{spassT?MELIA?iProver?Vampire?} and even higher-order \cite{satallax} theorem provers have
taken advantage of embedding sat-solvers too.

In such a scenario, it is essential that sat-solvers output not only a \emph{yes} or \emph{no}
answer, but also a model (in case of satisfiability) or a refutation (in case of unsatisfiability).
For DPLL- and CDCL-based sat-solvers, propositional resolution is an excellent proof system, since
refutations in this system can be generated with an acceptable efficiency overhead and they are
detailed enough to allow easy implementation of efficient proof checkers.

ToDo: unsat core, interpolants...

With the increase in the demand for proofs from sat-solvers, there has been a surge of techniques to
compress and improve such proofs in a post-processing stage. ToDo: briefly describe and list related
work here.

In this paper...  ToDo: modify and expand the abstract here\\
 describes a generalization of the {\LowerUnits} algorithm \cite{LURPI} for the compression
of propositional resolution proofs. The generalized algorithm, here called {\LowerUnivalents}, is
able to lower not only units but also proof nodes containing non-unit clauses, provided that their
literals satisfy some additional conditions. A formal proof that {\LowerUnivalents} always
compresses more than {\LowerUnits} is shown, and both algorithms are empirically compared on
thousands of proofs produced by the SMT-Solver \veriT.

ToDo: explain the organization of the paper here..



\section{Propositional Resolution Calculus}

A \emph{literal} is a propositional variable or the negation of a propositional variable. The \emph{dual} of a literal $\ell$ is denoted
$\dual{\ell}$ (i.e. for any propositional variable $p$, $\dual{p} =
\neg p$ and $\dual{\neg p} = p$) and the \emph{underlying variable} of a literal
$\ell$ is written $|\ell|$ (i.e. $|p| = |\neg p| = p$). The set of all literals is denoted $\mathcal{L}$. A \emph{clause} is a set of literals. $\bot$ denotes the \emph{empty clause}.


\newcommand{\axiom}[1]{\hat{#1}}
\newcommand{\n}{v}
\newcommand{\raiz}[1]{\rho(#1)}

\begin{definition}[Proof] 
\label{def:proof}
A directed acyclic graph $\langle V, E, \clause \rangle$, where $V$ is a set of
nodes and $E$ is a set of edges labeled by literals (i.e. $E \subset V \times
\mathcal{L} \times V$ and $\n_1 \xrightarrow{\ell} \n_2$ denotes an edge from
node $\n_1$ to node $\n_2$ labeled by $\ell$), is a proof of a clause $c$ iff
it is inductively constructible according to the following cases:
%
\begin{enumerate}
  \item If $\Gamma$ is a clause, $\axiom{\Gamma}$ denotes some proof $\langle \{ \n \}, \varnothing, \Gamma \} \rangle$, where $\n$ is a new node.
  \item If $\psi_L$ is a proof $\langle V_L, E_L, \clause_L \rangle$ and
    $\psi_R$ is a proof $\langle V_R, E_R, \clause_R \rangle$ and $\ell$ is a literal such that
    $\dual{\ell} \in \clause_L$ and $\ell \in \clause_R$, then
    $\psi_L \odot_\ell \psi_R$ denotes a proof 
    $$\langle 
    V_L \cup V_R \cup \{\n \},
    E_L \cup E_R \cup \{\n \xrightarrow{\dual{\ell}} \raiz{\psi_L}, \n \xrightarrow{\ell} \raiz{\psi_R}\}, 
    (\clause_L \setminus \{ \dual{\ell} \}) \cup (\clause_R \setminus \{ \ell \})
    \rangle$$
     where $\n$ is a new node and $\raiz{\varphi}$ denotes the root node of $\varphi$.
  \qed
\end{enumerate}
\end{definition}


\newcommand{\Vertices}[1]{V_{#1}}
\newcommand{\Edges}[1]{E_{#1}}
\newcommand{\Conclusion}[1]{c_{#1}}

\noindent
If $\n_1 \xrightarrow{\ell} \n_2$, then $\n_2$ is called a \emph{premise} of $\n_1$ and $\n_1$ is
called a \emph{child} of $\n_2$. The transitive closures of the premise and child relations are,
respectively, the \emph{ancestor} and \emph{descendent} relations. If $\psi = \varphi_L \odot
\varphi_R$, then $\varphi_L$ and $\varphi_R$ are \emph{direct subproofs} of $\psi$. The transitive
closure of the direct subproof relation is the \emph{subproof} relation.
%
\BWP{Before submitting, we should check which of these relations we actually use in the paper and
remove the ones that are not used.}  $\Vertices{\psi}$, $\Edges{\psi}$ and $\Conclusion{\psi}$
denote, respectively, the nodes, edges and the proven clause (conclusion) of $\psi$.

\newcommand{\Active}[2]{A_{#2}(#1)}
\begin{definition}[Active literals]
The set of active literals $\Active{\varphi}{\psi}$ of a subproof $\varphi$ of a proof $\psi$
are the labels of edges coming into $\varphi$'s root: 
$$
\Active{\varphi}{\psi} =
  \{\ell \ | \ \exists \varsigma \in \Vertices{\psi}. \ \varsigma \xrightarrow{\ell} \raiz{\varphi} \}
$$
\end{definition}

\SetKwFunction{Rec}{delete}
\SetKw{Let}{let}

\begin{algorithm}[bt]
  \KwIn{$\varphi$ a subproof of $\psi$}
  \KwIn{$D$ a set of subproofs}
  \BlankLine

  \newcommand{\fixL}{\ensuremath{\varphi'_L}}
  \newcommand{\fixR}{\ensuremath{\varphi'_R}}

  \uIf{$\varphi \in D$ or $\raiz{\varphi}$ has no premises}{
    \Return{$\varphi$} \;
  }
  \BlankLine

  \Else{
    \Let{$\varphi_L$, $\varphi_R$ and $\ell$} be such that
      $\varphi = \varphi_L \odot_\ell \varphi_R$ \;
    \Let{$\varphi'_L = $ \Rec{$\varphi_L$,$D$}} \;
    \Let{$\varphi'_R = $ \Rec{$\varphi_R$,$D$}} \;
    \BlankLine

    \uIf{$\varphi_L \in D$}
      { \Return{\fixR} \; }
    \uElseIf{$\varphi_R \in D$}
      { \Return{\fixL} \; }
    \BlankLine

    \uElseIf{$\dual{\ell} \notin \Conclusion{\fixL}$}
      { \Return{\fixL} \; }
    \uElseIf{$\ell \notin \Conclusion{\fixR}$}
      { \Return{\fixR} \; }
    \BlankLine

    \Else{ \Return{ \fixL~$\odot_\ell$~\fixR} \; }
  }

  \caption[.]{\FuncSty{delete}}
  \label{algo:del}
\end{algorithm}

In the context of proof compression, deletion of nodes from a proof will be needed. Algorithm
\ref{algo:del} describes the deletion operation used in this article. $\dn{\psi}{\varphi_1 \ldots
\varphi_n}$ denotes \Rec{$\psi$,$\{\varphi_1, \ldots , \varphi_n\}$}.
\JB{ TODO: rewrite this paragraph, addind the algorithm description. }

\begin{proposition} \label{prop:del_assoc}
\JB{ Proof: by induction }
For any proof $\psi$ and any sets $A$ and $B$ of $\psi$'s subproofs,
either $\dn{\psi}{A \cup B}  \in A \cup B$
and    $\dn{\dn{\psi}{A}}{B} \in A \cup B$,
or     $\dn{\psi}{A \cup B} = \dn{\dn{\psi}{A}}{B}$.
\end{proposition}


\begin{definition}[Valent literal]
In a proof $\psi$, a literal $\ell$ is valent for the subproof $\varphi$ if $\dual{\ell}$ belongs to
the conclusion of $\dn{\psi}{\varphi}$ but not to the conclusion of $\psi$.
\end{definition}

\begin{proposition} \label{prop:valentactive}
In a proof $\psi$, a valent literal of a subproof $\varphi$ is an active literal of $\varphi$.
\end{proposition}

\begin{proof}
Lines 2, 12, 14 and 16 from Algo. \ref{algo:del} can't introduce a new literal in the conclusion of
the subproof being processed. Let write $\ell$ for a valent literal of $\varphi$ in $\psi$. Because
there is only one subproof to be deleted, $\dual{\ell}$ can only be introduced when processing a
subproof $\varphi'$ such that $\raiz{\varphi'} \xrightarrow{\ell} \raiz{\varphi}$. \qed
\end{proof}

\begin{proposition}
\JB{ Proof: from Prop. \ref{prop:del_assoc} }
Given a proof $\psi$ and a set $D = \{\varphi_1 \ldots \varphi_n\}$ of $\psi$'s subproofs, $\forall
\ell \in \mathcal{L}$ s.t. $\ell$ is in the conclusion of $\dn{\psi}{D}$ but not in $\psi$'s
conclusion, then $\exists i$ s.t. $\dual{\ell}$ is a valent literal of $\varphi_i$ in $\psi$.
\end{proposition}



\section{LowerUnits}

When the root node of a subproof $\varphi$ as more than one child in a proof $\psi$ it might be
convenient to factor the corresponding resolutions. Lowering $\varphi$ is such a factorisation. A
new equivalent proof is constructed by removing $\varphi$ from $\psi$ and reintroducing it at the
bottom of the proof. Formaly, a subproof $\varphi$ in a proof $\psi$ can be lowered if there exists
a proof $\psi'$ and a literal $\ell$ such that $\psi' = \dn{\psi}{\varphi} \odot_a \varphi$ and
$\Conclusion{\psi'} \subseteq \Conclusion{\psi}$.

These idea has been introduce in \cite{LURPI} for the {\LowerUnits} algorithm. Units are subproofs
with a conclusion consisting of only one literal. Such a subproof can always be lowered. The
proposed algorithm lowers every unit with more than one child. Care is taken to reintroduce units in
an order corresponding to the ancestor relation : if a unit $\varphi_2$ is an ancestor of a unit
$\varphi_1$ then $\varphi_2$ has to be reintroduced after (ie below) $\varphi_1$.

A possible presentation of {\LowerUnits} is shown in Algorithm \ref{algo:LU}. Units are collected
during a first traversal. As this traversal is bottom-up, units are stored in a queue. The traversal
could have been top-down and units stored in a stack. Units are effectively removed during a second,
top-down traversal. The last step is the reintroduction of units.

\begin{algorithm}[bt]
  \KwIn {a proof $\psi$}
  \KwOut{a compressed proof $\psi'$}
  \BlankLine

  \SetKwData{Units}{Units}
  \Units $\leftarrow \varnothing$ \;
  \BlankLine

  \For{every subproof $\varphi$ in a bottom-up traversal}{
    \If{$\varphi$ is a unit and its root has more than one child}{Enqueue $\varphi$ in \Units \; }
  }
  \BlankLine

  $\psi' \leftarrow $ \Rec{$\psi$,$\Units$} \;
  \BlankLine

  \For{every unit $\varphi$ in \Units}{
    \Let{$\{\ell\} = \Conclusion{\varphi}$} \;
    \lIf{$\dual{\ell} \in \Conclusion{\psi'}$}{
    $\psi' \leftarrow \psi' \odot_\ell \varphi$ \;}
  }

  \caption{\LowerUnits}
  \label{algo:LU}
\end{algorithm}

\section{LowerUnivalents}

\begin{jb}
This is the main section. First we present formaly the principles of the algorithm. Then the partial
regularization. Then the algorithm. Then the proof it's always better than LU (and LUnivRPI always
better than LU.RPI).
\end{jb}

{\LowerUnits} obviously doesn't lower every lowerable subproofs. In particular, it doesn't take into
account the already lowered subproofs. For instance, if a unit $\varphi_1$ proving $\{a\}$ has
already been lowered, a subproof $\varphi_2$ with conclusion $\{\neg a,b\}$ may be lowered too and
reintroduced above $\varphi_1$. But care must be taken, because if $\neg a$ is a valent literal of
$\varphi_2$ then $a$ will be introduced in the proof by the deletion.

\begin{definition}[Univalent subproof]
A subproof $\varphi$ in a proof $\psi$ is \emph{univalent} w.r.t. a set $\Delta$ of literals if
$\varphi$ has exactly one valent literal $\ell$ in $\psi$, $\ell \notin \Delta$ and
$\Conclusion{\varphi} \subseteq \Delta \cup \left\{ \ell \right\}$. $\ell$ is called the univalent
literal of $\varphi$ in $\psi$ w.r.t.  $\Delta$.
\end{definition}

The principle of {\LowerUnivalents} is simply to lower every univalent subproofs. $\Delta$ is
initialized to the empty set. Then the dual of the univalent literals are incrementaly added to
$\Delta$. The proposition \ref{prop:LUniv} ensures that the conclusion of the resulting proof
subsumes the conclusion of the original one.

\begin{proposition} \label{prop:LUniv}
Given a proof $\psi$, if for an integer $n$ there is a sequence $U = (\varphi_1 \ldots \varphi_n)$
of $\psi$'s subproofs and a sequence $(\ell_1 \ldots \ell_n)$ of literals such that $\forall i \in
[1 \ldots n], \ell_i$ is the univalent literal of $\varphi_i$ w.r.t. $\Delta_{i-1} = \{\dual{\ell_1}
\ldots \dual{\ell_{i-1}}\}$, then the conclusion of
$$ \psi' = \dn{\psi}{U} \odot_{\ell_n} \varphi_n \ldots \odot_{\ell_1} \varphi_1 $$
subsumes the conclusion of $\psi$.
\end{proposition}

\begin{proof}
The proposition will be proved by induction on $n$, along with the fact that $\dn{\psi}{U} \notin
U$. Let suppose a subproof $\varphi_{n+1}$ of $\psi$ is univalent w.r.t. $\Delta_n$, with univalent
literal $\ell_{n+1}$.  Because $\ell_{n+1} \notin \Delta_n$, there exists a subproof of
$\dn{\psi}{U}$ which conclusion contains $\dual{\ell_{n+1}}$, therefore
$\dn{\dn{\psi}{U}}{\varphi_{n+1}} \notin U \cup \{\varphi_{n+1}\}$.  Let $\Gamma$ be the conclusion
of $\dn{\psi}{U}$. The conclusion of $ \psi' = \dn{\psi}{U \cup \{\varphi_{n+1}\}} =
\dn{\dn{\psi}{U}}{\varphi_{n+1}} $ is included in $\Gamma \cup \{\dual{\ell{n+1}}\}$. The conclusion
of $\psi' \odot_{\ell_{n+1}} \varphi_{n+1}$ is included in $\Gamma \cup \Delta_n$. As $\Gamma
\subseteq \Conclusion{\psi} \cup \Delta_n$, the conclusion of $\psi' \odot_{\ell_{n+1}}
\varphi_{n+1} \ldots \odot_{\ell_1} \varphi_1$ is included in $\Conclusion{\psi}$. \qed
\end{proof}

For this principle to lead to proof compression care must be taken of the order subproofs are
considered for lowering. Let suppose for instance that $\varphi_i, \varphi_j$ and $\varphi_k$ have
been selected to be lowered, $i < j < k$, $\varphi_j$ is a subproof of $\varphi_i$, $\dual{\ell_j}
\in \Conclusion{\varphi_k}$ and $\varphi_j$ is not a subproof of $\dn{\psi}{\varphi_i}$. In that
case $\varphi_j$ will have one more child in the resulting proof than in the original one.

\SetKwData{Univ}{Univalents}
\begin{algorithm}[bt]
  \KwIn {a proof $\psi$}
  \KwOut{a compressed proof $\psi'$}
  \BlankLine

  \SetKw{Push}{push}
  \SetKw{Pop} {pop}

  \Univ $\leftarrow \varnothing$ \;
  $\Delta \leftarrow \varnothing$ \;
  \BlankLine

  \For{every subproof $\varphi$ in a top-down traversal \label{line:LUniv:step1begin} }{
    $\psi' \leftarrow$ \Rec{$\varphi$,\Univ} \;
    \If{$\psi'$ is univalent w.r.t. $\Delta$ \label{line:LUniv:lunivtest} }{
      \Let{$\ell$} be the univalent literal \;
      \Push $\dual{\ell}$ onto $\Delta$ \;
      \Push $\psi'$     onto \Univ \label{line:LUniv:step1end} \;
    }
  }
  \BlankLine

  \tcp{$\psi' = \dn{\psi}{\Univ}$}
  \While{\Univ $\neq \varnothing$}{
    $\varphi \leftarrow$ \Pop from \Univ \;
    $\ell \leftarrow$ \Pop from $\Delta$ \;
    \lIf{$\ell \in \Conclusion{\psi'}$}{
    $\psi' \leftarrow \varphi \odot_\ell \psi'$ \;}
  }

  \caption{\LowerUnivalents}
  \label{algo:LUniv}
\end{algorithm}

To address this issue, {\LowerUnivalents} considers subproofs in a top-down traversal and deletes
already collected univalent subproofs at the same time, as shown in Algo. \ref{algo:LUniv}.
Actually, the first loop (line \ref{line:LUniv:step1begin} to \ref{line:LUniv:step1end}) can be
implemented as a recursive function extending a recursive implementation of \FuncSty{delete}. With
such an implementation, {\LowerUnivalents} could have a time complexity linear w.r.t. the size of
the proof, as long as the univalent test (at line \ref{line:LUniv:lunivtest}) can be performed in
constant bounded time.

Determining if a literal is valent takes time. But thanks to Prop.  \ref{prop:valentactive},
subproofs with one active literal which is not in $\Conclusion{\psi}$ could be considered instead
of subproofs with one valent literal.  If the active literal is not valent, the corresponding
subproof may not be reintroduced but still can be safely deleted.

While verifying if a subproof could be univalent, some incoming edges might be deleted. If a
subproof $\varphi_i$ has already been collected as univalent subproof with univalent literal
$\ell_i$ and the subproof being considered now has $\ell_i$ as active literal, the corresponding
incoming edges can be safely removed. Even if $\ell_i$ is valent, only $\dual{\ell_i}$ would be
introduced and that literal would be deleted when reintroducing $\varphi_i$. A modified
\FuncSty{delete} operation able to remove nodes and edges can easily be implemented.

\begin{algorithm}[bt]
  \KwIn {a proof $\psi$}
  \KwIn {a subproof $\varphi$}
  \KwIn {a set $\Delta$ of literal}
  \BlankLine

  \SetKwData{Activ}{ActiveLiterals}
  \Activ $\leftarrow \varnothing$ \;
  \BlankLine

  \For{each incoming edge $\n \xrightarrow{\ell} \raiz{\varphi}$ not marked for deletion }{
    \uIf{$\dual{\ell} \in \Delta$}{
      mark the edge for deletion \;
    }
    \uElseIf{$\ell \notin \Delta$, $\ell \in \Conclusion{\varphi}$ and
             $\ell \notin \Conclusion{\psi}$ }{
      add $\ell$ to \Activ \;
    }
  }
  \BlankLine

  \If{\Activ $= \{\ell\}$ and $\Conclusion{\varphi} \subseteq \Delta \cup \{\ell\}$ }{
    \Return{true} and \ArgSty{$\ell$} \;
  }
  \Else{\Return{false} \;}

  \caption[.]{\FuncSty{isUnivalent}}
  \label{algo:isUniv}
\end{algorithm}


\begin{jb}
At that point, I don't know if I should add a new algorithm with all the features I just mentioned.
This algorithm would take a lot of space if the new deleted algorithm is detailed.

I continue with the proof that LUniv compress at least as much as LU.
\end{jb}

\begin{proposition}
Given a proof $\psi$,
{\LowerUnits\FuncSty{(}$\psi$\FuncSty{)}}
has at least as many nodes as 
{\LowerUnivalents\FuncSty{(}$\psi$\FuncSty{)}}
if there are not two units in $\psi$ with the same conclusion.
\end{proposition}

\begin{proof}
A unit $\varphi$ has exactely one active literal $\ell$. Therefore $\varphi$ is collected by
{\LowerUnivalents} unless $\dual{\ell} \in \Delta$ or $\ell \in \Delta$. If $\dual{\ell} \in \Delta$
all the incoming edges to $\raiz{\varphi}$ are deleted. If $\ell \in \Delta$, all edges coming from
a descendent of $\raiz{\varphi}$ and labeled by $\dual{\ell}$ are deleted. In particular, for every
edge $\n \xrightarrow{\ell} \raiz{\varphi}$ the edge $\n \xrightarrow{\dual{\ell}} \n'$ is deleted.
Moreover, as $\ell$ is the only literal of $\varphi$'s conclusion, $\varphi$ is propagated down the
proof until the univalent subproof with valent literal $\dual{\ell}$ is reintroduced. \qed
\end{proof}

In the case where there are at least two units with the same conclusion in $\psi$, the resulting
compressed proof depends on the order units are collected. For both algorithms, only one of these
units may appear in the resulting compressed proof.



\section{Combining {\LowerUnivalents} with {\RPI}}
\begin{jb}
This section has to be written.
\end{jb}

{\LowerUnits} has been successfully composed with the {\RPI} algorithm presented in \cite{LURPI}.
Both sequential compositions achieve very good compression ratio in reasonnable amount of time.
Unfortunately, none of them is always better than the other and there is actually no heuristic to
choose which one to apply a priori.
\JB{ TODO: Rewrite this paragraph. }



\section{Experiments}

\begin{table}[ht]
  \centering
  \begin{tabular}{lrrr}
    \toprule
    \multirow{2}{*}{Algorithm} & Nodes       & Axioms      & \multirow{2}{*}{Speed} \\
                               & compression & compression & \\
    \midrule
    LU         &  7.5 \% &  0.0 \% & 21.7 n/ms \\
    LUniv      &  8.0 \% &  0.8 \% &  7.6 n/ms \\
    RPILU      & 22.3 \% &  3.6 \% &  8.3 n/ms \\
    RPILUniv   & 22.4 \% &  3.6 \% &  5.0 n/ms \\
    LURPI      & 21.9 \% &  3.1 \% & 15.2 n/ms \\
    LUnivRPI   & 22.3 \% &  3.6 \% &  8.1 n/ms \\
    Best LU    & 22.4 \% &  3.7 \% &  5.4 n/ms \\
    Best LUniv & 22.5 \% &  3.8 \% &  3.1 n/ms \\
    \bottomrule
  \end{tabular}
  \caption{Total compression ratios}
\end{table}


\include{LU_charts}
\include{RPILU_charts}
\include{LURPI_charts}
\include{best_charts}

\section{Conclusions}

\bibliographystyle{splncs}
\bibliography{../biblio}

\end{document}
