\documentclass{llncs}

\usepackage{xcolor}
\usepackage{enumitem,amsmath,amssymb}
\usepackage{stmaryrd}    % needed for \mapsfrom
\usepackage[linesnumbered,boxed,noline,noend]{algorithm2e}
\usepackage{bussproofs}
\def\defaultHypSeparation{\hskip.1in}

\usepackage{tikz}
\usepackage{subfig}
\usepackage{array,booktabs,multirow}

\usepackage{logictools}
\usepackage{prooftheory}
\usepackage{comment}
\usepackage{mathenvironments}


\title{Propositional Resolution Proof Compression by Lowering Nodes}

\author{
  Joseph Boudou\inst{1}
  \thanks{This work was supported by the Google Summer of Code program.}
  \and 
  Bruno Woltzenlogel Paleo\inst{2}
}

\authorrunning{J.\~Boudou \and B.\~Woltzenlogel Paleo}

\institute{
  Universit\'e Paul Sabatier, Toulouse \\
  \email{joseph.boudou@matabio.net}
  \and 
  Vienna University of Technology \\
  \email{bruno@logic.at}
}




\includeonly{}
\begin{document}

\maketitle


\begin{abstract}
This paper describes a generalization of the {\LowerUnits} algorithm \cite{LURPI}
for the compression of propositional resolution proofs. 
The generalized algorithm, here called {\LowerUnivalents}, is
able to lower not only units but also proof nodes containing non-unit clauses, 
provided that their literals satisfy some additional conditions. 
A formal proof that {\LowerUnivalents} always compresses more than {\LowerUnits} is shown, 
and both algorithms are empirically compared on
thousands of proofs produced by the SMT-Solver \veriT.
\end{abstract}



\section{Introduction}

Sat-solvers are among the most successful automated deduction tools available today. As standalone
tools, they can already be applied to a wide range of problems, especially considering that, due to
the NP-completeness of propositional satisfiability \cite{cook}, any NP problem can be encoded as a
propositional formula. And, nevertheless, despite the theoretical difficulty associated with NP
problems, state-of-the-art sat-solving techniques perform surprisingly well in practice
\cite{sat-competition}. With the aim of leveraging this efficiency, sat-solvers have been embedded
into various other automated deduction tools that target problems described in more expressive
logics. The most prominent examples are SMT-solvers \cite{veriT}, for checking satisfiability modulo
theories for equality, linear arithmetic, bit-vectors, arrays and others. But more recently,
interactive proof assistants \cite{isabelle-blanchette-boehme} and automated first-order
\cite{spassT?MELIA?iProver?Vampire?} and even higher-order \cite{satallax} theorem provers have
taken advantage of embedding sat-solvers too.

In such a scenario, it is essential that sat-solvers output not only a \emph{yes} or \emph{no}
answer, but also a model (in case of satisfiability) or a refutation (in case of unsatisfiability).
For DPLL- and CDCL-based sat-solvers, propositional resolution is an excellent proof system, since
refutations in this system can be generated with an acceptable efficiency overhead and they are
detailed enough to allow easy implementation of efficient proof checkers.

ToDo: unsat core, interpolants...

With the increase in the demand for proofs from sat-solvers, there has been a surge of techniques to
compress and improve such proofs in a post-processing stage. ToDo: briefly describe and list related
work here.

In this paper...  ToDo: modify and expand the abstract here\\
 describes a generalization of the {\LowerUnits} algorithm \cite{LURPI} for the compression
of propositional resolution proofs. The generalized algorithm, here called {\LowerUnivalents}, is
able to lower not only units but also proof nodes containing non-unit clauses, provided that their
literals satisfy some additional conditions. A formal proof that {\LowerUnivalents} always
compresses more than {\LowerUnits} is shown, and both algorithms are empirically compared on
thousands of proofs produced by the SMT-Solver \veriT.

ToDo: explain the organization of the paper here..



\section{Propositional Resolution Calculus}

A \emph{literal} is a propositional variable or the negation of a propositional variable. The \emph{dual} of a literal $\ell$ is denoted
$\dual{\ell}$ (i.e. for any propositional variable $p$, $\dual{p} =
\neg p$ and $\dual{\neg p} = p$) and the \emph{underlying variable} of a literal
$\ell$ is written $|\ell|$ (i.e. $|p| = |\neg p| = p$). The set of all literals is denoted $\mathcal{L}$. A \emph{clause} is a set of literals. $\bot$ denotes the \emph{empty clause}.


\newcommand{\axiom}[1]{\hat{#1}}
\newcommand{\n}{v}
\newcommand{\raiz}[1]{\rho(#1)}

\begin{definition}[Proof] 
\label{def:proof}
A directed acyclic graph $\langle V, E, \clause \rangle$, where $V$ is a set of
nodes and $E$ is a set of edges labeled by literals (i.e. $E \subset V \times
\mathcal{L} \times V$ and $\n_1 \xrightarrow{\ell} \n_2$ denotes an edge from
node $\n_1$ to node $\n_2$ labeled by $\ell$), is a proof of a clause $c$ iff
it is inductively constructible according to the following cases:
%
\begin{enumerate}
  \item If $\Gamma$ is a clause, $\axiom{\Gamma}$ denotes some proof $\langle \{ \n \}, \varnothing, \Gamma \} \rangle$, where $\n$ is a new node.
  \item If $\psi_L$ is a proof $\langle V_L, E_L, \clause_L \rangle$ and
    $\psi_R$ is a proof $\langle V_R, E_R, \clause_R \rangle$ and $\ell$ is a literal such that
    $\dual{\ell} \in \clause_L$ and $\ell \in \clause_R$, then
    $\psi_L \odot_\ell \psi_R$ denotes a proof 
    $$\langle 
    V_L \cup V_R \cup \{\n \},
    E_L \cup E_R \cup \{\n \xrightarrow{\dual{\ell}} \raiz{\psi_L}, \n \xrightarrow{\ell} \raiz{\psi_R}\}, 
    (\clause_L \setminus \{ \dual{\ell} \}) \cup (\clause_R \setminus \{ \ell \})
    \rangle$$
     where $\n$ is a new node and $\raiz{\varphi}$ denotes the root node of $\varphi$.
  \qed
\end{enumerate}
\end{definition}


\newcommand{\Vertices}[1]{V_{#1}}
\newcommand{\Edges}[1]{E_{#1}}
\newcommand{\Conclusion}[1]{c_{#1}}

\noindent
If $\n_1 \xrightarrow{\ell} \n_2$, then $\n_2$ is called a \emph{premise} of $\n_1$ and $\n_1$ is
called a \emph{child} of $\n_2$. The transitive closures of the premise and child relations are,
respectively, the \emph{ancestor} and \emph{descendent} relations. If $\psi = \varphi_L \odot
\varphi_R$, then $\varphi_L$ and $\varphi_R$ are \emph{direct subproofs} of $\psi$. The transitive
closure of the direct subproof relation is the \emph{subproof} relation.
%
\BWP{Before submitting, we should check which of these relations we actually use in the paper and
remove the ones that are not used.}  $\Vertices{\psi}$, $\Edges{\psi}$ and $\Conclusion{\psi}$
denote, respectively, the nodes, edges and the proven clause (conclusion) of $\psi$.

\newcommand{\Active}[2]{A_{#2}(#1)}
\begin{definition}[Active literals]
The set of active literals $\Active{\varphi}{\psi}$ of a subproof $\varphi$ of a proof $\psi$
are the labels of edges coming into $\varphi$'s root: 
$$
\Active{\varphi}{\psi} =
  \{\ell \ | \ \exists \varsigma \in \Vertices{\psi}. \ \varsigma \xrightarrow{\ell} \raiz{\varphi} \}
$$
\end{definition}

\SetKwFunction{Rec}{delete}
\SetKw{Let}{let}

\begin{algorithm}[bt]
  \KwIn{$\varphi$ a subproof of $\psi$}
  \KwIn{$D$ a set of subproofs}
  \BlankLine

  \newcommand{\fixL}{\ensuremath{\varphi'_L}}
  \newcommand{\fixR}{\ensuremath{\varphi'_R}}

  \uIf{$\varphi \in D$ or $\raiz{\varphi}$ has no premises}{
    \Return{$\varphi$} \;
  }
  \BlankLine

  \Else{
    \Let{$\varphi_L$, $\varphi_R$ and $\ell$} be such that
      $\varphi = \varphi_L \odot_\ell \varphi_R$ \;
    \Let{$\varphi'_L = $ \Rec{$\varphi_L$,$D$}} \;
    \Let{$\varphi'_R = $ \Rec{$\varphi_R$,$D$}} \;
    \BlankLine

    \uIf{$\varphi_L \in D$}
      { \Return{\fixR} \; }
    \uElseIf{$\varphi_R \in D$}
      { \Return{\fixL} \; }
    \BlankLine

    \uElseIf{$\dual{\ell} \notin \Conclusion{\fixL}$}
      { \Return{\fixL} \; }
    \uElseIf{$\ell \notin \Conclusion{\fixR}$}
      { \Return{\fixR} \; }
    \BlankLine

    \Else{ \Return{ \fixL~$\odot_\ell$~\fixR} \; }
  }

  \caption[.]{\FuncSty{delete}}
  \label{algo:del}
\end{algorithm}

In the context of proof compression, deletion of nodes from a proof will be needed. Algorithm
\ref{algo:del} describes the deletion operation used in this article. $\dn{\psi}{\varphi_1 \ldots
\varphi_n}$ denotes \Rec{$\psi$,$\{\varphi_1, \ldots , \varphi_n\}$}.
\JB{ TODO: rewrite this paragraph, addind the algorithm description. }

\begin{proposition} \label{prop:del_assoc}
\JB{ Proof: by induction }
For any proof $\psi$ and any sets $A$ and $B$ of $\psi$'s subproofs,
either $\dn{\psi}{A \cup B}  \in A \cup B$
and    $\dn{\dn{\psi}{A}}{B} \in A \cup B$,
or     $\dn{\psi}{A \cup B} = \dn{\dn{\psi}{A}}{B}$.
\end{proposition}


\begin{definition}[Valent literal]
In a proof $\psi$, a literal $\ell$ is valent for the subproof $\varphi$ if $\dual{\ell}$ belongs to
the conclusion of $\dn{\psi}{\varphi}$ but not to the conclusion of $\psi$.
\end{definition}

\begin{proposition}
In a proof $\psi$, a valent literal of a subproof $\varphi$ is an active literal of $\varphi$.
\end{proposition}

\begin{proof}
Lines 2, 12, 14 and 16 from Algo. \ref{algo:del} can't introduce a new literal in the conclusion of
the subproof being processed. Let write $\ell$ for a valent literal of $\varphi$ in $\psi$. Because
there is only one subproof to be deleted, $\dual{\ell}$ can only be introduced when processing a
subproof $\varphi'$ such that $\raiz{\varphi'} \xrightarrow{\ell} \raiz{\varphi}$. \qed
\end{proof}

\begin{proposition}
\JB{ Proof: from Prop. \ref{prop:del_assoc} }
Given a proof $\psi$ and a set $D = \{\varphi_1 \ldots \varphi_n\}$ of $\psi$'s subproofs, $\forall
\ell \in \mathcal{L}$ s.t. $\ell$ is in the conclusion of $\dn{\psi}{D}$ but not in $\psi$'s
conclusion, then $\exists i$ s.t. $\dual{\ell}$ is a valent literal of $\varphi_i$ in $\psi$.
\end{proposition}



\section{LowerUnits}

When the root node of a subproof $\varphi$ as more than one child in a proof $\psi$ it might be
convenient to factor the corresponding resolutions. Lowering $\varphi$ is such a factorisation. A
new equivalent proof is constructed by removing $\varphi$ from $\psi$ and reintroducing it at the
bottom of the proof. Formaly, a subproof $\varphi$ in a proof $\psi$ can be lowered if there exists
a proof $\psi'$ and a literal $\ell$ such that $\psi' = \dn{\psi}{\varphi} \odot_a \varphi$ and
$\Conclusion{\psi'} \subseteq \Conclusion{\psi}$.

These idea has been introduce in \cite{LURPI} for the {\LowerUnits} algorithm. Units are subproofs
with a conclusion consisting of only one literal. Such a subproof can always be lowered. The
proposed algorithm lowers every unit with more than one child. Care is taken to reintroduce units in
an order corresponding to the ancestor relation : if a unit $\varphi_2$ is an ancestor of a unit
$\varphi_1$ then $\varphi_2$ has to be reintroduced after (ie below) $\varphi_1$.

A possible presentation of {\LowerUnits} is shown in Algorithm \ref{algo:LU}. Units are collected
during a first traversal. As this traversal is bottom-up, units are stored in a queue. The traversal
could have been top-down and units stored in a stack. Units are effectively removed during a second,
top-down traversal. The last step is the reintroduction of units.

\begin{algorithm}[bt]
  \KwIn {a proof $\psi$}
  \KwOut{a compressed proof $\psi'$}
  \BlankLine

  \SetKwData{Units}{Units}
  \Units $\leftarrow \varnothing$ \;
  \BlankLine

  \For{every subproof $\varphi$ in a bottom-up traversal}{
    \If{$\varphi$ is a unit and its root has more than one child}{Enqueue $\varphi$ in \Units \; }
  }
  \BlankLine

  $\psi' \leftarrow $ \Rec{$\psi$,$\Units$} \;
  \BlankLine

  \For{every unit $\varphi$ in \Units}{
    \Let{$\{\ell\} = \Conclusion{\varphi}$} \;
    \lIf{$\dual{\ell} \in \Conclusion{\psi'}$}{
    $\psi' \leftarrow \psi' \odot_\ell \varphi$ \;}
  }

  \caption{\LowerUnits}
  \label{algo:LU}
\end{algorithm}

{\LowerUnits} has been successfully composed with the {\RPI} algorithm presented in \cite{LURPI}.
Both sequential compositions achieve very good compression ratio in reasonnable amount of time.
Unfortunately, none of them is always better than the other and there is actually no heuristic to
choose which one to apply a priori.
\JB{ TODO: Rewrite this paragraph. }

\section{LowerUnivalents}

\begin{jb}
This is the main section. First we present formaly the principles of the algorithm. Then the partial
regularization. Then the algorithm. Then the proof it's always better than LU (and LUnivRPI always
better than LU.RPI).
\end{jb}

{\LowerUnits} obviously doesn't lower every lowerable subproofs. In particular, it doesn't take into
account the already lowered subproofs. For instance, if a unit $\varphi_1$ proving $\{a\}$ has
already been lowered, a subproof $\varphi_2$ with conclusion $\{\neg a,b\}$ may be lowered too and
reintroduced above $\varphi_1$. But care must be taken, because if $\neg a$ is a valent literal of
$\varphi_2$ then $a$ will be introduced in the proof by the deletion.

\begin{definition}[Univalent subproof]
A subproof $\varphi$ in a proof $\psi$ is \emph{univalent} w.r.t. a set $\Delta$ of literals if
$\varphi$ has one valent literal $\ell$ in $\psi$ and $\Conclusion{\varphi} \subseteq \Delta \cup
\left\{ \ell \right\}$. $\ell$ is call the univalent literal of $\varphi$ in $\psi$ w.r.t.
$\Delta$.
\end{definition}

The principle of {\LowerUnivalents} is simply to lower every univalent subproofs. $\Delta$ is
initialized to the empty set. Then the dual of the univalent literals are incrementaly added to
$\Delta$. The proposition \ref{prop:LUniv} ensures that the conclusion of the resulting proof
subsumes the conclusion of the original proof.

\begin{proposition} \label{prop:LUniv}
Given a proof $\psi$, if for an integer $n$ there is a set $U = \{\varphi_1 \ldots \varphi_n\}$ of
$\psi$'s subproofs and a set $D = \{\Delta_0 \ldots \Delta_n\}$ of sets of literals such that
$$ \Delta_0 = \varnothing $$
$$ \forall i \in [1 \ldots n], \varphi_i \text{ is univalent w.r.t. } \Delta_{i-1} $$
$$ \forall i \in [1 \ldots n], \Delta_i = \Delta_{i-1} \cup \{\dual{\ell_i}\} \text{ with } \ell_i
\text{ being the univalent literal of } \varphi_i $$
therefore the conclusion of
$$ \psi' = \dn{\psi}{U} \odot_{\ell_n} \varphi_n \ldots \odot_{\ell_1} \varphi_1 $$
subsumes the conclusion of $\psi$.
\end{proposition}

\begin{proof}
The proposition will be proved by induction on $n$. Let suppose a subproof $\varphi_{n+1}$ of $\psi$
is univalent w.r.t. $\Delta_n$, with univalent literal $\ell_{n+1}$. Let $\Gamma$ be the conclusion
of $\dn{\psi}{U}$. The conclusion of $ \psi' = \dn{\psi}{U \cup \{\varphi_{n+1}\}} =
\dn{\dn{\psi}{U}}{\varphi} $ is included in $\Gamma \cup \{\dual{\ell{n+1}}\}$. The conclusion of
$\psi' \odot_{\ell_{n+1}} \varphi_{n+1}$ is included in $\Gamma \cup \Delta_n$. As $\Gamma \subseteq
\Conclusion{\psi} \cup \Delta_n$, the conclusion of $\psi' \odot_{\ell_{n+1}} \varphi_{n+1} \ldots
\odot_{\ell_1} \varphi_1$ is included in $\Conclusion{\psi}$. \qed
\end{proof}


\begin{jb}
Everything below and until the next section is garbage.
\end{jb}

To state which conditions $\eta$ must satisfy to be lowered without changing the
proof's conclusion, the lower problem has to be redefined as follow.

\begin{definition}[Lowerable subproof]
Given a proof $\psi$ of $\Gamma$ and a subproof $\varphi$, a subproof $\eta$ from $\varphi$ is lowerable
below $\varphi$ if there exists a literal $\ell$ and a proof $\psi'$ of $\Gamma' \subseteq
\Gamma$ such that
\begin{equation}
  \psi' = \rn{\psi}{\varphi}{\left(\dn{\varphi}{\eta}\right) \odot_\ell \eta}
\end{equation}
\end{definition}
The previous definition is very general. The lowerable subproof introduction presented in the
previous Section can be obtained when $\varphi = \psi$. In the context of proof compression,
lowering a subproof is wanted to reduce the number of $\eta$'s root's children. For instance, it
could be required that every path from the root of $\psi$ to the root of $\eta$ goes through the
root of $\varphi$. In this case, $\eta$'s root is guaranted to have only one child in $\psi'$.

\begin{definition}[Lowered part]
If a proof $\psi$ can be written as
\begin{equation}
  \psi = \eta_1 \odot_{\ell_1} ( \eta_2 \odot_{\ell_2} ( \ldots (\eta_n \odot_{\ell_n} \varphi)
          \ldots ))
\end{equation}
then the pair $\langle L,\Delta \rangle$ in which $L$ is the sequence $(\eta_1,\ldots,\eta_n)$ of
proofs and $\Delta$ the sequence $(\ell_1,\ldots,\ell_n)$ of literals is called a lowered part of
$\psi$ below $\varphi$.
\end{definition}
Once again this is a broad definition. In the context of proof compression the root of each proof
$\eta_i \in L$ would usualy have exactely one child in $\psi$.

\begin{definition}[Univalent subproof]
A subproof $\eta$ of $\Gamma$ in a proof $\psi$ is \emph{univalent} w.r.t. a set $\Delta$ of literals if $\eta$ has
exactely one valent literal $\ell$ in $\psi$ and $\Gamma \subseteq \Delta \cup \left\{ \ell
\right\}$.
\end{definition}

\begin{proposition}
If $\langle L,\Delta \rangle$ is a lowered part of $\psi$ below $\varphi$ and $\eta$ a subproof of
$\varphi$ which is univalent in $\varphi$ w.r.t. $\Delta$, then $\eta$ is lowerable in $\psi$ below $\varphi$.
\end{proposition}

\begin{proof}
Let call $\Gamma$ the conclusion of $\varphi$.  The only valent literal of $\eta$ in $\varphi$ being
$\ell$, the conclusion of $\dn{\varphi}{\eta}$ is a subset of $\Gamma \cup \{\dual{\ell}\}$. As the
conclusion of $\eta$ is a subset of $\Delta \cup \{\ell\}$, the conclusion of $\left(
\dn{\varphi}{\eta} \right) \odot_\ell \eta$ is a subset of $\Gamma \cup \Delta$. Finaly, $\Delta$ is
a set of safe literals for $\varphi$ in $\psi$. \qed
\end{proof}


\section{Experiments}

\begin{jb}
LU vs LUniv ; RPI[3]LU vs RPI[3]LUniv ; LUnivRPI vs LU.RPI.
\end{jb}


\BWP{1) If possible, add RP and RPI to this table too. Otherwise we will only be comparing our own algorithms.}
\BWP{2) Also, it seems that we are only showing the non-sequential combinations here (or is RPILU actually "RPI.LU"??). If we could also show the sequential combinations, we would compare their speeds and show that the non-sequential combinations are faster, and that LUniv contributed to this.}
\begin{table}[ht]
  \centering
  \begin{tabular}{lrrr}
    \toprule
    \multirow{2}{*}{Algorithm} & Nodes       & Axioms      & \multirow{2}{*}{Speed} \\
                               & compression & compression & \\
    \midrule
    LU         &  7.5 \% &  0.0 \% & 21.7 n/ms \\
    LUniv      &  8.0 \% &  0.8 \% &  7.6 n/ms \\
    RPILU      & 22.3 \% &  3.6 \% &  8.3 n/ms \\
    RPILUniv   & 22.4 \% &  3.6 \% &  5.0 n/ms \\
    LURPI      & 21.9 \% &  3.1 \% & 15.2 n/ms \\
    LUnivRPI   & 22.3 \% &  3.6 \% &  8.1 n/ms \\
    Best LU    & 22.4 \% &  3.7 \% &  5.4 n/ms \\
    Best LUniv & 22.5 \% &  3.8 \% &  3.1 n/ms \\
    \bottomrule
  \end{tabular}
  \caption{Total compression ratios}
\end{table}

\BWP{3) So, LUniv is about 3 times slower than LU. Can we blame implementation details (e.g. the fact that we use lists instead of sets for conclusion clauses) for this?}

\BWP{4) I think you forgot to push the files with charts}


\include{LU_charts}
\include{RPILU_charts}
\include{LURPI_charts}
\include{best_charts}

\section{Conclusions}

\bibliographystyle{splncs}
\bibliography{../biblio}

\end{document}
